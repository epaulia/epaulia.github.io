<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-Content-Type-Options" content="nosniff">
    <meta http-equiv="X-Frame-Options" content="DENY">
    <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com; style-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com; img-src 'self' data:; font-src 'self' https://cdnjs.cloudflare.com; connect-src 'self'; worker-src 'self' blob:;">
    <meta http-equiv="Referrer-Policy" content="strict-origin-when-cross-origin">
    <meta name="description" content="Case study demonstrating 27.3% improvement in ML model accuracy through strategic data preprocessing. Real-world housing price prediction with comprehensive data quality pipeline.">
    <meta name="keywords" content="data quality, machine learning, data preprocessing, ML accuracy, feature engineering, data science case study, housing prediction">
    <meta name="author" content="Eugene Paulia">
    <meta property="og:title" content="Impact of Data Quality on ML: A Practical Case Study">
    <meta property="og:description" content="Case study demonstrating 27.3% improvement in ML model accuracy through strategic data preprocessing.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://epaulia.github.io/blog/data-quality-ml-impact.html">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Impact of Data Quality on ML: A Practical Case Study">
    <meta name="twitter:description" content="Case study demonstrating 27.3% improvement in ML model accuracy through strategic data preprocessing.">
    <title>Impact of Data Quality on ML: A Practical Case Study | Eugene Paulia</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw==" crossorigin="anonymous" referrerpolicy="no-referrer">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerpolicy="no-referrer">
    <link rel="stylesheet" href="../css/blog.css">
    <link rel="icon" type="image/png" href="../logos/favicon.png">
</head>
<body>
    <a href="all-projects.html" class="back-to-home" id="back-link">
        <i class="fas fa-arrow-left"></i>
        Back to Projects
    </a>
    
    <header class="blog-header">
        <canvas id="particles-canvas"></canvas>
        <div class="header-content">
            <div class="blog-date">June 2025</div>
            <h1 class="blog-title">Impact of Data Quality on ML</h1>
            <div class="blog-author">by Eugene Paulia</div>
            <div class="blog-tags">
                <span class="blog-tag">Machine Learning</span>
                <span class="blog-tag">Data Quality</span>
                <span class="blog-tag">UntappedEnergy</span>
            </div>
        </div>
    </header>
    
    <article class="blog-content">
        <p>This case study demonstrates the impact that data preprocessing can have on machine learning model performance using a real-world housing dataset. The project showcases how strategic data quality improvements can deliver immediate, substantial improvements in AI project success rates.</p>

        <div class="highlight-box">
            <h3>Key Achievement</h3>
            <p><strong>27.3% improvement in model accuracy</strong> through comprehensive data preprocessing alone.</p>
        </div>

        <div class="highlight-box github-box">
            <h3><i class="fab fa-github"></i> Project Repository</h3>
            <p>Explore the complete implementation, Jupyter notebooks, and detailed analysis:</p>
            <a href="https://github.com/epaulia/untappedEnergy" target="_blank" rel="noopener noreferrer" class="github-link">
                <i class="fab fa-github"></i> View on GitHub
            </a>
        </div>

        <h2>The Challenge</h2>
        <p>Industry statistics reveal a sobering reality about AI project success rates:</p>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-number">85%</div>
                <div class="stat-label">AI projects fail to deliver on promises</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">70%</div>
                <div class="stat-label">Failures due to data quality issues</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">$5T</div>
                <div class="stat-label">Annual revenue lost globally</div>
            </div>
        </div>

        <h2>The Experiment: Housing Price Prediction</h2>
        
        <h3>Dataset Overview</h3>
        <ul>
            <li><strong>Source</strong>: Sberbank Russian Housing Market (Kaggle)</li>
            <li><strong>Size</strong>: 27,000 records with 20 features</li>
            <li><strong>Task</strong>: Predict housing prices in rubles</li>
            <li><strong>Target</strong>: `price_doc` (housing prices)</li>
        </ul>

        <h3>Initial Data State</h3>
        <p>The raw dataset exhibited typical real-world data quality issues:</p>
        <ul>
            <li>Missing values across multiple columns (up to 50% in some features)</li>
            <li>Inconsistent data types (numeric values stored as strings)</li>
            <li>No proper normalization or feature engineering</li>
            <li>Outliers and noise in the target variable</li>
            <li>Categorical variables requiring encoding</li>
        </ul>

        <h2>Methodology</h2>

        <h3>Baseline Model (Minimal Processing)</h3>
        <p><strong>Approach</strong>: Use only complete numeric columns with zero preprocessing</p>
        <ul>
            <li><strong>Features used</strong>: 6 columns (only complete numeric)</li>
            <li><strong>Model</strong>: Ridge Regression (α=10.0)</li>
            <li><strong>Data preparation</strong>: None beyond basic column selection</li>
        </ul>

        <pre><code class="language-python"># Only use numeric columns with no missing values
numeric_complete = X_train.select_dtypes(include=[np.number]).dropna(axis=1)
baseline_model = Ridge(alpha=10.0, random_state=42)
baseline_model.fit(numeric_complete, y_train)</code></pre>

        <h3>Advanced Model (Comprehensive Preprocessing Pipeline)</h3>
        <p><strong>Approach</strong>: Industry-standard preprocessing with custom transformers</p>

        <h4>Custom Preprocessing Components</h4>

        <h5>1. HybridImputer: Intelligent Missing Value Handling</h5>
        <ul>
            <li><strong>Numeric features</strong>: KNN imputation (k=5) using distance-weighted neighbors</li>
            <li><strong>Categorical features</strong>: Mode imputation</li>
        </ul>

        <h5>2. SelectiveFeatureEngineer: Domain-driven Feature Creation</h5>
        <ul>
            <li>Living space efficiency ratio</li>
            <li>Average room size indicator</li>
            <li>Floor desirability ratio</li>
            <li>Log-transformed area features</li>
            <li>Amenity accessibility score</li>
        </ul>

        <h5>3. SmartCategoricalEncoder: Adaptive Encoding Strategy</h5>
        <ul>
            <li>High cardinality (>5 categories): Frequency encoding</li>
            <li>Low cardinality (≤5 categories): One-hot encoding</li>
            <li>Handles unseen categories gracefully</li>
        </ul>

        <pre><code class="language-python"># Advanced preprocessing pipeline
focused_preprocessor = Pipeline([
    ('imputer', HybridImputer()),
    ('feature_engineer', SelectiveFeatureEngineer()), 
    ('encoder', SmartCategoricalEncoder()),
    ('scaler', StandardScaler())
])

model_pipeline = Pipeline([
    ('preprocessor', focused_preprocessor),
    ('regressor', Ridge(alpha=10.0, random_state=42))
])</code></pre>

        <h2>Results</h2>

        <h3>Performance Comparison</h3>
        <div class="highlight-box">
            <table>
                <thead>
                    <tr>
                        <th>Approach</th>
                        <th class="text-center">RMSE (Rubles)</th>
                        <th class="text-center">Features Used</th>
                        <th class="text-center">R² Score</th>
                        <th class="text-center">Improvement</th>
                    </tr>
                </thead>
                <tbody>
                    <tr class="border-bottom">
                        <td data-label="Approach"><strong>Baseline</strong></td>
                        <td class="text-center" data-label="RMSE (Rubles)">5,887,234</td>
                        <td class="text-center" data-label="Features Used">6</td>
                        <td class="text-center" data-label="R² Score">0.42</td>
                        <td class="text-center" data-label="Improvement">-</td>
                    </tr>
                    <tr class="highlight-row">
                        <td data-label="Approach"><strong>Advanced</strong></td>
                        <td class="text-center" data-label="RMSE (Rubles)">4,270,891</td>
                        <td class="text-center" data-label="Features Used">15+</td>
                        <td class="text-center" data-label="R² Score">0.67</td>
                        <td class="text-center" data-label="Improvement"><strong>27.3%</strong></td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h2>Key Technical Implementations</h2>

        <h3>Strategic Feature Engineering</h3>
        <pre><code class="language-python"># Living efficiency ratio - captures space utilization
living_efficiency = life_sq / full_sq

# Room size indicator - proxy for luxury
avg_room_size = full_sq / num_room

# Floor desirability - middle floors often preferred
floor_ratio = floor / max_floor

# Amenity score - accessibility to services
amenity_score = Σ(1 / distance_to_amenity)</code></pre>

        <h3>Context-Aware Missing Value Handling</h3>
        <pre><code class="language-python">class HybridImputer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # Learn imputation parameters from training data
        self.numeric_imputer = KNNImputer(n_neighbors=5)
        self.categorical_imputer = SimpleImputer(strategy='most_frequent')
        return self
    
    def transform(self, X):
        # Apply learned transformations
        X_numeric = self.numeric_imputer.transform(X.select_dtypes(include=[np.number]))
        X_categorical = self.categorical_imputer.transform(X.select_dtypes(include=['object']))
        return np.hstack([X_numeric, X_categorical])</code></pre>

        <h3>Adaptive Categorical Encoding</h3>
        <pre><code class="language-python">def smart_encode_categorical(X, threshold=5):
    """Adaptive encoding based on cardinality"""
    for col in X.select_dtypes(include=['object']):
        unique_count = X[col].nunique()
        
        if unique_count > threshold:
            # High cardinality: use frequency encoding
            X[col] = X[col].map(X[col].value_counts(normalize=True))
        else:
            # Low cardinality: use one-hot encoding
            X = pd.get_dummies(X, columns=[col], drop_first=True)
    
    return X</code></pre>

        <h2>Business Impact</h2>
        <p>For a housing market application:</p>
        <ul>
            <li><strong>Baseline RMSE</strong>: ₽5.9M average prediction error</li>
            <li><strong>Advanced RMSE</strong>: ₽4.3M average prediction error</li>
            <li><strong>Practical benefit</strong>: ₽1.6M more accurate predictions on average</li>
        </ul>

        <p>This improvement translates to:</p>
        <ul>
            <li>More accurate property valuations</li>
            <li>Better investment decisions</li>
            <li>Reduced financial risk in real estate transactions</li>
        </ul>

        <h2>Lessons Learned</h2>

        <h3>1. Preprocessing ROI is Immediate</h3>
        <ul>
            <li><strong>Time investment</strong>: ~4 hours for comprehensive pipeline</li>
            <li><strong>Performance gain</strong>: 27.3% error reduction</li>
            <li><strong>Effort-to-impact ratio</strong>: Exceptionally high</li>
        </ul>

        <h3>2. Feature Engineering Amplifies Signal</h3>
        <p>Raw features often don't capture domain relationships:</p>
        <ul>
            <li>Room efficiency ratios matter more than raw square footage</li>
            <li>Accessibility scores matter more than individual distances</li>
            <li>Relative positions (floor ratios) matter more than absolute values</li>
        </ul>

        <h3>3. Pipeline Design Prevents Common Pitfalls</h3>
        <ul>
            <li><strong>Data leakage</strong>: Fit transformers only on training data</li>
            <li><strong>Overfitting</strong>: Selective feature engineering vs. automated feature generation</li>
            <li><strong>Production issues</strong>: Handle unseen categories gracefully</li>
        </ul>

        <h2>Conclusion</h2>
        <p>This case study demonstrates that <strong>strategic data preprocessing delivers immediate, substantial improvements</strong> in machine learning performance. The progression from baseline to advanced preprocessing showcases how systematic data quality improvements compound to deliver substantial business value.</p>

        <div class="highlight-box">
            <h3>Key Takeaways</h3>
            <ol>
                <li><strong>Clean data trumps complex algorithms</strong>: 27.3% improvement through preprocessing alone</li>
                <li><strong>Domain knowledge guides feature engineering</strong>: Understanding housing markets led to effective feature creation</li>
                <li><strong>Pipeline design matters</strong>: Proper architecture prevents common pitfalls</li>
                <li><strong>Categorical data is valuable</strong>: Smart encoding preserves important information</li>
                <li><strong>ROI is immediate</strong>: High-impact improvements with reasonable time investment</li>
            </ol>
        </div>

        <p><em>This case study was presented by GroupLabs at the "AI-Ready or AI-Hopeful?" workshop for UntappedEnergy, demonstrating practical approaches to improving AI project success rates through systematic data quality practices for UntappedEnergy.</em></p>
    </article>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js" integrity="sha512-axJX7DJduStuBB8ePC8ryGzacZPr3rdLaIDZitiEgWWk2gsXxEFlm4UW0iNzj2h3wp5mOylgHAzBzM4nRSvTZA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-python.min.js" integrity="sha512-lPbwGiPWBLOs6Vq0Kkm4T/oYPQwXWqm8KkZTXvxGZqg4TjGZVUVJV2a6Z1rI04yBXTKJ4HhU/xEzoyHvTWFLg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script>
        // Check referrer and update back link
        document.addEventListener('DOMContentLoaded', function() {
            const referrer = document.referrer;
            const backLink = document.getElementById('back-link');
            
            if (referrer.includes('all-projects.html')) {
                backLink.href = 'all-projects.html';
            }
        });

        // Particle system animation
        const canvas = document.getElementById('particles-canvas');
        const ctx = canvas.getContext('2d');
        
        function resizeCanvas() {
            canvas.width = canvas.offsetWidth;
            canvas.height = canvas.offsetHeight;
        }
        
        resizeCanvas();
        window.addEventListener('resize', resizeCanvas);
        
        class Particle {
            constructor() {
                this.reset();
            }
            
            reset() {
                this.x = Math.random() * canvas.width;
                this.y = Math.random() * canvas.height;
                this.vx = Math.random() * 0.2 - 0.1;
                this.vy = Math.random() * 0.2 - 0.1;
                this.radius = Math.random() * 2 + 1;
                this.opacity = Math.random() * 0.5 + 0.2;
            }
            
            update() {
                this.x += this.vx;
                this.y += this.vy;
                
                if (this.x < 0 || this.x > canvas.width) this.vx *= -1;
                if (this.y < 0 || this.y > canvas.height) this.vy *= -1;
            }
            
            draw() {
                ctx.beginPath();
                ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2);
                ctx.fillStyle = `rgba(97, 218, 251, ${this.opacity})`;
                ctx.fill();
            }
        }
        
        const particles = Array.from({ length: 100 }, () => new Particle());
        
        function animate() {
            requestAnimationFrame(animate);
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            particles.forEach(particle => {
                particle.update();
                particle.draw();
            });
            
            particles.forEach((p1, i) => {
                particles.slice(i + 1).forEach(p2 => {
                    const dx = p1.x - p2.x;
                    const dy = p1.y - p2.y;
                    const distance = Math.sqrt(dx * dx + dy * dy);
                    
                    if (distance < 100) {
                        ctx.beginPath();
                        ctx.moveTo(p1.x, p1.y);
                        ctx.lineTo(p2.x, p2.y);
                        ctx.strokeStyle = `rgba(97, 218, 251, ${0.2 * (1 - distance / 100)})`;
                        ctx.stroke();
                    }
                });
            });
        }
        
        animate();
    </script>
</body>
</html> 